# About Me
I am a seasoned Senior Data Scientist with a rich background spanning 6 years in NLP, Reinforcement Learning, and Data Analytics. Proficient in leveraging cutting-edge technologies such as LLM open source platforms like Hugging Face, Lanchain, and Streamlit. My expertise extends to cloud services (Snowflake, AWS, Azure, GCP) and essential programming tools (Jupyter, PyCharm, Git). I possess strong capabilities in Machine Learning, Deep Learning, and constructing effective Recommendation Systems. Known for my ability to swiftly adapt to diverse data and business challenges, I bring not only technical proficiency but also robust communication skills, establishing myself as a creative team player. Committed to delivering well-written, object-oriented code, I am enthusiastic about pushing the boundaries of innovation in the field.

# Work Experience
## Senior Data Scientist | Stora Enso 
### (Full time employee)
 
**TECH STACK:** Chatbots Orchestration, Hugging Face (Open-source NLP library), Lanchain, Streamlit, 
Azure Cloud Integration, Design Patterns Implementation, Azure AutoML SDK, LSTM Models for, Forecasting, Deep Neural Networks for Propensity Score, Scikit-Learn, Collaborative Filtering for Recommender Systems, Bayesian Statistics for Dynamic Pricing, Python, SQL, SnowFlake, GIT, Azure Cloud, Databricks, MongoDB

### AI Acceleration with Generative AI
*January 2024 - Present*

In the AI Acceleration with Generative AI project, I played a pivotal role in democratizing generative AI capabilities throughout the company. Key contributions include:
- Orchestrating chatbots with a combination of closed and open-source tools.
- Utilizing Hugging Face, Lanchain, and Streamlit for UI enhancements.
- Seamlessly integrating deployed chatbots into Azure Cloud for scalability and flexibility.
- Advancing the company's AI capabilities, fostering innovation, and improving operational efficiency.

### Precision Forestry
*August 2023 - December 2023*

In the Precision Forestry project, I focused on optimizing code structure through the implementation of design patterns. Key achievements include:
- Refactoring regression models and constructing baseline models with Azure AutoML SDK.
- Streamlining the development process and improving overall codebase efficiency.

### Selfly Store
*June 2022 - June 2023*

#### Introduction:
In my role on the Selfly Store project, I leveraged AI to enhance the intelligence of vending machines, making them AI-driven and improving the overall shopping experience.

#### Patentable Solution:
The innovative AI solution developed in this project is poised to be patentable, with a patent currently in the process of being filed in the US.

#### Project Stages:

**Analytics/Engineering Stage:**
- Managed and processed extensive cloud-stored data.
- Designed a preprocessing pipeline for crucial product inventory in JSON files.
- Used algorithms like DFS to compress the dataset for analytics.
- Improved product categorization with a logic-based approach and addressed uncategorized products using a TF-IDF-based classifier.
- Created a cabinet lifetime value model, treating cabinets as customers for performance assessment with CLV scores.

**Artificial Intelligence Stage:**
- Implemented forecasting using LSTM models and ensemble methods for accurate predictions.
- Developed deep neural network-based models for propensity score.
- Built collaborative filtering and hybrid systems for personalized recommendations in recommender systems.
- Utilized Bayesian statistics to optimize prices for increased revenue and customer satisfaction in dynamic pricing.

## Data Scientist | TUI Global
### (Full time employee)

**TECH STACK:** Lifetimes Python Package (Probabilistic modeling), Snowflake, Tableau, XGBoost, Stacked Model (Combining booking and clickstream data), Weighted Average Model, RandomForest, MLFlow (Model tracking), Python, SQL, Google Cloud, Amazon Web Services, GitLab

### PROJECT: Customer Life Time Value | Mar 2021 - Nov 2021   
Primary Goal: Build a Customer Life Time Value model to demonstrate the financial return per customer and make better business decisions by focusing on profitable customers. 

Solution: We build a probabilistic model using Lifetimes python package and a Neural Network model. The final results were stored in Snowflake and also delivered a Tableau dashboard to share the results with relevant stakeholders. 

### PROJECT: Recommender Systems | Mar 2021 - Present
Primary Goal: Build a personalisation model to recommend destinations and hotels at a user level. 

Solution: Build an item based collaborative filtering recommender and a user based probabilistic model to recommend destinations at a user level. The classifier model was built using XGBoost since it gave us the best results after applying hyper parameter tuning. This recommendations are being send to customers via email.The final results were stored in Snowflake and also delivered a Tableau dashboard to share the results with relevant stakeholders. We are currently working on building and API for model deployment.  

### PROJECT: Hotel Search Ranking Model | Mar 2021 - Present
Primary Goal: To build a a solution that creates the perfect hotel ranking for users. The models was trained using both booking and click stream data.

Solution: A stacked model combining both booking data and web/clickstream data. The result of the 2 individual models were finally combined using weights(weighted average model) to generate a final ranking result. We used a weighted average approach and trained classifier using RandomForest and XGBoost in order to train the model using all possible features. All results of the process were stored in MLFlow and the model will be used as a part of the search section in the web page. 

### POC - ML Pipeline Automation Package | Mar 2021 - Present
The initial idea popped up when I notice that daily data science coding tasks could be automated to deliver faster baseline models, tuned models and mock ups. 

Primary Goal: Build a solution to automate the daily machine learning workflow to be able to invest more time in other relevant activities of a data science project. 

Solution: Build a set of python functions and classes covering all stages of a typical machine learning pipeline (data transformation - encoding - feature engineering - modelling). The structure of the functions is flexible enough to let the developer ingest more functions/classes depending on the needs of a particular project. The user is able to choose the order of specific ML steps/stages and which transformations gave the best result/scores/error. The output of every individual stage are stored in MLFlow and local folders.